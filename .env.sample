# =============================================================================
# OKTA MCP SERVER - ENVIRONMENT CONFIGURATION
# =============================================================================
# This file contains all environment variables needed to configure the 
# Okta MCP Server with OAuth proxy support.
#
# Instructions:
# 1. Copy this file to .env
# 2. Fill in your actual values (remove placeholder text)
# 3. Never commit .env to version control
# =============================================================================

# =============================================================================
# OKTA CONFIGURATION (Required)
# =============================================================================
# Your Okta organization URL - replace with your actual Okta domain
OKTA_CLIENT_ORGURL=https://dev-1602.okta.com
OKTA_ORG_URL=https://dev-1602.okta.com

# Okta API Token - generate from Admin > Security > API > Tokens
# Read-only permissions are sufficient for most operations
OKTA_API_TOKEN=

# =============================================================================
# OAUTH CLIENT CONFIGURATION (Required for OAuth Proxy)
# =============================================================================
# Create an OAuth application in Okta Admin Console:
# 1. Go to Applications > Create App Integration
# 2. Choose "Web Application" 
# 3. Set Sign-in redirect URI to: http://localhost:3001/oauth/callback
# 4. Note the Client ID and Secret below

OKTA_CLIENT_ID=your-oauth-client-id
OKTA_CLIENT_SECRET=your-oauth-client-secret

# OAuth Security Settings
OKTA_OAUTH_AUDIENCE=fctrid-okta-mcp-server
OAUTH_REDIRECT_URI=http://localhost:3001/oauth/callback
OAUTH_REQUIRE_HTTPS=false


# ==========================================================================

# RBAC GROUP-TO-ROLE MAPPINGS (Required for OAuth)
# =============================================================================
# Map Okta groups to user roles for access control.
# Users are assigned the highest role based on their group membership.
# 
# Format: GROUP_TO_ROLE_<ROLE>=<OKTA_GROUP_NAME(S)>
# - Use exact Okta group names (case-sensitive)
# - Multiple groups: separate with commas
# - Groups with spaces: use quotes around the entire value
# - Empty value means no users will have that role

# Examples of group mapping configurations:
# GROUP_TO_ROLE_SUPER_ADMIN="IT Administrators,Platform Team"
# GROUP_TO_ROLE_SECURITY_ADMIN="Security Team,Identity Admins  
# GROUP_TO_ROLE_VIEWER="All Users,Contractors,Help Desk"

# Super Admin: Full access to all 18 tools (policy management, etc.)
GROUP_TO_ROLE_SUPER_ADMIN=""

# Security Admin: Access to 17 tools (user factors, app assignments, policies)
GROUP_TO_ROLE_SECURITY_ADMIN=""

# Viewer: Access to 12 read-only tools (basic user/group/app queries)
GROUP_TO_ROLE_VIEWER=""



# Note: Users not in any mapped groups will have no tool access (secure default)

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# API Rate Limiting - number of parallel threads for Okta API calls
# Adjust based on your Okta org's rate limits (typically 10-20)
OKTA_CONCURRENT_LIMIT=15

# Optional: Session security for production deployments
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#SESSION_SECRET_KEY=your-base64-encoded-32-byte-key

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================
# Choose your AI provider: vertex_ai, openai, azure_openai, openai_compatible, anthropic
AI_PROVIDER=openai_compatible

# -----------------------------------------------------------------------------
# OpenAI Configuration
# -----------------------------------------------------------------------------
#OPENAI_API_KEY=
#OPENAI_REASONING_MODEL=gpt-4o
#OPENAI_CODING_MODEL=gpt-4o

# -----------------------------------------------------------------------------
# Azure OpenAI Configuration  
# -----------------------------------------------------------------------------
#AZURE_OPENAI_KEY=your-api-key
#AZURE_OPENAI_ENDPOINT=your-endpoint
#AZURE_OPENAI_VERSION=2024-07-01-preview
#AZURE_OPENAI_REASONING_MODEL=gpt-4
#AZURE_OPENAI_CODING_MODEL=gpt-4-turbo

# -----------------------------------------------------------------------------
# Vertex AI Configuration
# -----------------------------------------------------------------------------
#VERTEX_AI_SERVICE_ACCOUNT_FILE=path/to/service-account.json
#VERTEX_AI_REASONING_MODEL=gemini-2.5-pro-exp-03-25
#VERTEX_AI_CODING_MODEL=gemini-2.5-pro-exp-03-25
#GOOGLE_CLOUD_PROJECT=your-project-id

# -----------------------------------------------------------------------------
# Anthropic Configuration
# -----------------------------------------------------------------------------
#ANTHROPIC_API_KEY=
#ANTHROPIC_REASONING_MODEL=claude-3-5-sonnet-20241022

# -----------------------------------------------------------------------------
# OpenAI Compatible APIs (Fireworks, Groq, etc.)
# -----------------------------------------------------------------------------
OPENAI_COMPATIBLE_REASONING_MODEL=accounts/fireworks/models/deepseek-v3
OPENAI_COMPATIBLE_CODING_MODEL=accounts/fireworks/models/deepseek-v3
OPENAI_COMPATIBLE_BASE_URL=https://api.fireworks.ai/inference/v1
OPENAI_COMPATIBLE_TOKEN=

# Optional: Custom HTTP headers for OpenAI compatible APIs
#CUSTOM_HTTP_HEADERS={"x-ai-organization": "org-0a1b2c3d49j"}

# -----------------------------------------------------------------------------
# Ollama (Local AI) Configuration
# -----------------------------------------------------------------------------
#AI_PROVIDER=openai_compatible
#OPENAI_COMPATIBLE_REASONING_MODEL=qwen2.5:latest
#OPENAI_COMPATIBLE_CODING_MODEL=qwen2.5-coder:latest
#OPENAI_COMPATIBLE_BASE_URL=http://localhost:11434/v1
#OPENAI_COMPATIBLE_TOKEN=ollama

